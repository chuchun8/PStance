{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import preprocessor as p \n",
    "import re\n",
    "import json\n",
    "import wordninja\n",
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from transformers import AutoModel, BertForMaskedLM, AdamW\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, BertweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "\n",
    "def load_data(filename):\n",
    "\n",
    "    filename = [filename]\n",
    "    concat_text = pd.DataFrame()\n",
    "    raw_text = pd.read_csv(filename[0],usecols=[0], encoding='ISO-8859-1')\n",
    "    raw_label = pd.read_csv(filename[0],usecols=[2], encoding='ISO-8859-1')\n",
    "    raw_target = pd.read_csv(filename[0],usecols=[1], encoding='ISO-8859-1')\n",
    "    label = pd.DataFrame.replace(raw_label,['FAVOR','NONE','AGAINST'], [1,2,0])\n",
    "    concat_text = pd.concat([raw_text, label, raw_target], axis=1)\n",
    "    concat_text = concat_text[concat_text.Stance != 2]\n",
    "    \n",
    "    return(concat_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "\n",
    "def data_clean(strings, norm_dict):\n",
    "    \n",
    "    p.set_options(p.OPT.URL,p.OPT.EMOJI,p.OPT.RESERVED)\n",
    "    clean_data = p.clean(strings)  # using lib to clean URL, emoji...\n",
    "    clean_data = re.sub(r\"#SemST\", \"\", clean_data)\n",
    "    clean_data = re.findall(r\"[A-Za-z#@]+|[,.!?&/\\<>=$]|[0-9]+\",clean_data)\n",
    "    clean_data = [[x.lower()] for x in clean_data]\n",
    "    \n",
    "    for i in range(len(clean_data)):\n",
    "        if clean_data[i][0] in norm_dict.keys():\n",
    "            clean_data[i][0] = norm_dict[clean_data[i][0]]\n",
    "            continue\n",
    "        if clean_data[i][0].startswith(\"#\") or clean_data[i][0].startswith(\"@\"):\n",
    "            clean_data[i] = wordninja.split(clean_data[i][0]) # split compound hashtags\n",
    "    clean_data = [j for i in clean_data for j in i]\n",
    "\n",
    "    return clean_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Clean All Data\n",
    "\n",
    "def clean_all(filename, norm_dict):\n",
    "    \n",
    "    concat_text = load_data(filename)\n",
    "    raw_data = concat_text['Tweet'].values.tolist() \n",
    "    label = concat_text['Stance'].values.tolist()\n",
    "    x_target = concat_text['Target'].values.tolist()\n",
    "    clean_data = [None for _ in range(len(raw_data))]\n",
    "    \n",
    "    for i in range(len(raw_data)):\n",
    "        clean_data[i] = data_clean(raw_data[i], norm_dict)\n",
    "        x_target[i] = data_clean(x_target[i], norm_dict)\n",
    "    \n",
    "    return clean_data,label,x_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "\n",
    "def convert_data_to_ids(tokenizer, target, text):\n",
    "    \n",
    "    input_ids, seg_ids, attention_masks, sent_len = [], [], [], []\n",
    "    for tar, sent in zip(target, text):\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            ' '.join(tar),                  # Target to encode\n",
    "                            ' '.join(sent),                 # Sentence to encode\n",
    "                            add_special_tokens = True,      # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = 128,               # Pad & truncate all sentences\n",
    "                            padding = 'max_length',\n",
    "                            return_attention_mask = True,   # Construct attention masks\n",
    "                       )\n",
    "\n",
    "        # Add the encoded sentence to the list.    \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        seg_ids.append(encoded_dict['token_type_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "        sent_len.append(sum(encoded_dict['attention_mask']))\n",
    "    \n",
    "    return input_ids, seg_ids, attention_masks, sent_len\n",
    "    \n",
    "def data_helper_bert(x_train_all,x_val_all,x_test_all,model_select):\n",
    "    \n",
    "    print('Loading data')\n",
    "    \n",
    "    x_train,y_train,x_train_target = x_train_all[0],x_train_all[1],x_train_all[2]                                                \n",
    "    x_val,y_val,x_val_target = x_val_all[0],x_val_all[1],x_val_all[2]\n",
    "    x_test,y_test,x_test_target = x_test_all[0],x_test_all[1],x_test_all[2]\n",
    "                                                         \n",
    "    print(\"Length of x_train: %d, the sum is: %d\"%(len(x_train), sum(y_train)))\n",
    "    print(\"Length of x_val: %d, the sum is: %d\"%(len(x_val), sum(y_val)))\n",
    "    print(\"Length of x_test: %d, the sum is: %d\"%(len(x_test), sum(y_test)))\n",
    "    \n",
    "    # get the tokenizer\n",
    "    if model_select == 'Bertweet':\n",
    "        tokenizer = BertweetTokenizer.from_pretrained(\"vinai/bertweet-base\", normalization=True)\n",
    "    elif model_select == 'Bert':\n",
    "        tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "        \n",
    "    # tokenization\n",
    "    x_train_input_ids, x_train_seg_ids, x_train_atten_masks, x_train_len = \\\n",
    "                    convert_data_to_ids(tokenizer, x_train_target, x_train)\n",
    "    x_val_input_ids, x_val_seg_ids, x_val_atten_masks, x_val_len = \\\n",
    "                    convert_data_to_ids(tokenizer, x_val_target, x_val)\n",
    "    x_test_input_ids, x_test_seg_ids, x_test_atten_masks, x_test_len = \\\n",
    "                    convert_data_to_ids(tokenizer, x_test_target, x_test)\n",
    "#     print(x_test_input_ids[0])\n",
    "    x_train_all = [x_train_input_ids,x_train_seg_ids,x_train_atten_masks,y_train,x_train_len]\n",
    "    x_val_all = [x_val_input_ids,x_val_seg_ids,x_val_atten_masks,y_val,x_val_len]\n",
    "    x_test_all = [x_test_input_ids,x_test_seg_ids,x_test_atten_masks,y_test,x_test_len]\n",
    "    \n",
    "    return x_train_all,x_val_all,x_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# BERT/BERTweet\n",
    "\n",
    "class stance_classifier(nn.Module):\n",
    "\n",
    "    def __init__(self,num_labels,model_select):\n",
    "\n",
    "        super(stance_classifier, self).__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        if model_select == 'Bertweet':\n",
    "            self.bert = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "        elif model_select == 'Bert':\n",
    "            self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.linear = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        \n",
    "    def forward(self, x_input_ids, x_seg_ids, x_atten_masks, x_len):\n",
    "        \n",
    "        last_hidden = self.bert(input_ids=x_input_ids, \\\n",
    "                                attention_mask=x_atten_masks, token_type_ids=x_seg_ids, \\\n",
    "                               )\n",
    "        \n",
    "        query = last_hidden[0][:,0]\n",
    "        query = self.dropout(query)\n",
    "        \n",
    "        linear = self.relu(self.linear(query))\n",
    "        out = self.out(linear)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "def compute_f1(preds, y):\n",
    "    \n",
    "    rounded_preds = F.softmax(preds)\n",
    "    _, indices = torch.max(rounded_preds, 1)\n",
    "                \n",
    "    correct = (indices == y).float()\n",
    "    acc = correct.sum()/len(correct) # compute accuracy\n",
    "    \n",
    "    y_pred = np.array(indices.cpu().numpy())\n",
    "    y_true = np.array(y.cpu().numpy())\n",
    "    result = precision_recall_fscore_support(y_true, y_pred, average=None, labels=[0,1])\n",
    "#     print(result[2][0],result[2][1])\n",
    "    f1_average = (result[2][0]+result[2][1])/2 # average F1 score of Favor and Against\n",
    "        \n",
    "    return acc, f1_average, result[0], result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Main \n",
    "\n",
    "def data_loader(x_all, batch_size, data_type):\n",
    "    \n",
    "    x_input_ids = torch.tensor(x_all[0], dtype=torch.long).cuda()\n",
    "    x_seg_ids = torch.tensor(x_all[1], dtype=torch.long).cuda()\n",
    "    x_atten_masks = torch.tensor(x_all[2], dtype=torch.long).cuda()\n",
    "    y = torch.tensor(x_all[3], dtype=torch.long).cuda()\n",
    "    x_len = torch.tensor(x_all[4], dtype=torch.long).cuda()\n",
    "\n",
    "    tensor_loader = TensorDataset(x_input_ids,x_seg_ids,x_atten_masks,y,x_len)\n",
    "    if data_type == 'train':\n",
    "        data_loader = DataLoader(tensor_loader, shuffle=True, batch_size=batch_size)\n",
    "    else:\n",
    "        data_loader = DataLoader(tensor_loader, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    return x_input_ids, x_seg_ids, x_atten_masks, y, x_len, data_loader\n",
    "    \n",
    "def sep_test_set(input_data):\n",
    "    \n",
    "    # split the combined test set for Trump, Biden and Bernie\n",
    "    data_list = [input_data[:777], input_data[777:1522], input_data[1522:2157]]\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "def run_classifier(input_word_pair,model_select,train_mode):\n",
    "    \n",
    "    random_seeds = [0,1,14,15,16,17,19]\n",
    "    target_word_pair = input_word_pair\n",
    "    \n",
    "    #Creating Normalization Dictionary\n",
    "    with open(\"./noslang_data.json\", \"r\") as f:\n",
    "        data1 = json.load(f)\n",
    "    data2 = {}\n",
    "    with open(\"./emnlp_dict.txt\",\"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            row = line.split('\\t')\n",
    "            data2[row[0]] = row[1].rstrip()\n",
    "    normalization_dict = {**data1,**data2}\n",
    "\n",
    "    for target_index in range(len(target_word_pair)):\n",
    "        best_result, best_val = [], []\n",
    "        for seed in random_seeds:    \n",
    "            print(\"current random seed: \", seed)\n",
    "\n",
    "            if train_mode == \"unified\":\n",
    "                filename1 = '/home/ubuntu/Stance_ACL2021/raw_train_all.csv'\n",
    "                filename2 = '/home/ubuntu/Stance_ACL2021/raw_val_all.csv'\n",
    "                filename3 = '/home/ubuntu/Stance_ACL2021/raw_test_all.csv'\n",
    "            elif train_mode == \"adhoc\":\n",
    "                filename1 = '/home/ubuntu/Stance_ACL2021/raw_train_'+target_word_pair[target_index]+'.csv'\n",
    "                filename2 = '/home/ubuntu/Stance_ACL2021/raw_val_'+target_word_pair[target_index]+'.csv'\n",
    "                filename3 = '/home/ubuntu/Stance_ACL2021/raw_test_'+target_word_pair[target_index]+'.csv'\n",
    "            x_train,y_train,x_train_target = clean_all(filename1, normalization_dict)\n",
    "            x_val,y_val,x_val_target = clean_all(filename2, normalization_dict)\n",
    "            x_test,y_test,x_test_target = clean_all(filename3, normalization_dict)\n",
    "                \n",
    "            num_labels = len(set(y_train))\n",
    "#             print(x_train_target[0])\n",
    "            x_train_all = [x_train,y_train,x_train_target]\n",
    "            x_val_all = [x_val,y_val,x_val_target]\n",
    "            x_test_all = [x_test,y_test,x_test_target]\n",
    "            \n",
    "            # set up the random seed\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed) \n",
    "\n",
    "            # prepare for model\n",
    "            x_train_all,x_val_all,x_test_all = data_helper_bert(x_train_all,x_val_all,x_test_all,model_select)\n",
    "#             print(x_test_all[0][0])\n",
    "            x_train_input_ids, x_train_seg_ids, x_train_atten_masks, y_train, x_train_len, trainloader = \\\n",
    "                                        data_loader(x_train_all, batch_size, 'train')\n",
    "            x_val_input_ids, x_val_seg_ids, x_val_atten_masks, y_val, x_val_len, valloader = \\\n",
    "                                        data_loader(x_val_all, batch_size, 'val')                            \n",
    "            x_test_input_ids, x_test_seg_ids, x_test_atten_masks, y_test, x_test_len, testloader = \\\n",
    "                                        data_loader(x_test_all, batch_size, 'test')\n",
    "\n",
    "            model = stance_classifier(num_labels,model_select).cuda()\n",
    "\n",
    "            for n,p in model.named_parameters():\n",
    "                if \"bert.embeddings\" in n:\n",
    "                    p.requires_grad = False\n",
    "            optimizer_grouped_parameters = [\n",
    "                {'params': [p for n, p in model.named_parameters() if n.startswith('bert.encoder')] , 'lr': lr},\n",
    "                {'params': [p for n, p in model.named_parameters() if n.startswith('bert.pooler')] , 'lr': 1e-3},\n",
    "                {'params': [p for n, p in model.named_parameters() if n.startswith('linear')], 'lr': 1e-3},\n",
    "                {'params': [p for n, p in model.named_parameters() if n.startswith('out')], 'lr': 1e-3}\n",
    "                ]\n",
    "            \n",
    "            loss_function = nn.CrossEntropyLoss(reduction='sum')\n",
    "            optimizer = AdamW(optimizer_grouped_parameters)\n",
    "            \n",
    "            sum_loss = []\n",
    "            sum_val = []\n",
    "            train_f1_average = []\n",
    "            val_f1_average = []\n",
    "            if train_mode == \"unified\":\n",
    "                test_f1_average = [[] for i in range(3)]\n",
    "            elif train_mode == \"adhoc\":\n",
    "                test_f1_average = [[]]\n",
    "\n",
    "            for epoch in range(0, total_epoch):\n",
    "                print('Epoch:', epoch)\n",
    "                train_loss, valid_loss = [], []\n",
    "                model.train()\n",
    "                for input_ids,seg_ids,atten_masks,target,length in trainloader:\n",
    "                    optimizer.zero_grad()\n",
    "                    output1 = model(input_ids, seg_ids, atten_masks, length)\n",
    "                    loss = loss_function(output1, target)\n",
    "                    loss.backward()\n",
    "                    nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "                    optimizer.step()\n",
    "                    train_loss.append(loss.item())\n",
    "                sum_loss.append(sum(train_loss)/len(x_train))  \n",
    "                print(sum_loss[epoch])\n",
    "\n",
    "                # evaluation on dev set\n",
    "                model.eval()\n",
    "                val_preds = []\n",
    "                with torch.no_grad():\n",
    "                    for input_ids,seg_ids,atten_masks,target,length in valloader: \n",
    "                        pred1 = model(input_ids, seg_ids, atten_masks, length) \n",
    "                        val_preds.append(pred1)\n",
    "                pred1 = torch.cat(val_preds, 0)\n",
    "                acc, f1_average, precision, recall = compute_f1(pred1,y_val)\n",
    "                val_f1_average.append(f1_average)\n",
    "                \n",
    "                # evaluation on test set\n",
    "                with torch.no_grad():\n",
    "                    test_preds = []\n",
    "                    for input_ids,seg_ids,atten_masks,target,length in testloader:\n",
    "                        pred1 = model(input_ids, seg_ids, atten_masks, length)\n",
    "                        test_preds.append(pred1)\n",
    "                    pred1 = torch.cat(test_preds, 0)\n",
    "                    if train_mode == \"unified\":\n",
    "                        pred1_list = sep_test_set(pred1)\n",
    "                        y_test_list = sep_test_set(y_test)\n",
    "                    else:\n",
    "                        pred1_list = [pred1]\n",
    "                        y_test_list = [y_test]\n",
    "                        \n",
    "                    for ind in range(len(y_test_list)):\n",
    "                        pred1 = pred1_list[ind]\n",
    "                        acc, f1_average, precision, recall = compute_f1(pred1,y_test_list[ind])\n",
    "                        test_f1_average[ind].append(f1_average)\n",
    "            \n",
    "            best_epoch = [index for index,v in enumerate(val_f1_average) if v == max(val_f1_average)][-1] \n",
    "            best_result.append([f1[best_epoch] for f1 in test_f1_average])\n",
    "\n",
    "            print(\"******************************************\")\n",
    "            print(\"dev results with seed {} on all epochs\".format(seed))\n",
    "            print(val_f1_average)\n",
    "            best_val.append(val_f1_average[best_epoch])\n",
    "            print(\"******************************************\")\n",
    "            print(\"test results with seed {} on all epochs\".format(seed))\n",
    "            print(test_f1_average)\n",
    "            print(\"******************************************\")\n",
    "        \n",
    "        # model that performs best on the dev set is evaluated on the test set\n",
    "        print(\"model performance on the test set: \")\n",
    "        print(best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run classifier in unified setting\n",
    "\n",
    "lr = 2e-5\n",
    "batch_size = 32\n",
    "total_epoch = 3\n",
    "run_classifier(['all'],'Bertweet','unified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run classifier in adhoc setting\n",
    "\n",
    "lr = 2e-5\n",
    "batch_size = 32\n",
    "total_epoch = 3\n",
    "run_classifier(['trump2'],'Bertweet','adhoc')\n",
    "run_classifier(['biden2'],'Bertweet','adhoc')\n",
    "run_classifier(['bernie2'],'Bertweet','adhoc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
